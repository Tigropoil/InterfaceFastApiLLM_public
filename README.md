# FastAPI_LLM
An API based on FastAPI to access and manage AI model on a server or a distant computer.
You can customize the FastAPI route to add or delete functionnalities.

You'll need the Ollama app and download model from it then that's all set.

Installation :
 - Pull the archive
 - Create a virtual environnement (python -m venv .venv)
 - Activate the environnement ()
 - Install the requierements (pip install -r /requierements.txt)
 For local use :
 - Launch SERVER/main.py in a dedicated terminal
 - Launch CLIENT/app.py in a dedicated terminal

DONE :
 - UI : You can connect to your server with IP address and port, select your model from the installed ones, send request to your models

TO DO :
 - New API route : Install new models with API, delete new models too.
 - Add checkBox in the IU to enable the index mode.
 - Scroll all the way down after each response or keep the scroll at the bottom
 - Chat history
